{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.dataset as ds\n",
    "import gcsfs\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Initialize GCS file system\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "\n",
    "# GCS base path\n",
    "gcs_base_path = \"gs://arc-ctc-scbasecamp/2025-02-25/\"\n",
    "\n",
    "# STARsolo feature type\n",
    "feature_type = \"GeneFull_Ex50pAS\"\n",
    "\n",
    "# Metadata path\n",
    "metadata_path = os.path.join(gcs_base_path, \"metadata\", feature_type)\n",
    "\n",
    "# Get the sample metadata file path for Homo sapiens\n",
    "sample_metadata_path = os.path.join(metadata_path, \"Homo_sapiens\", \"sample_metadata.parquet\")\n",
    "\n",
    "# Load the metadata\n",
    "sample_metadata = ds.dataset(sample_metadata_path, filesystem=fs, format=\"parquet\").to_table().to_pandas()\n",
    "\n",
    "# Filter for A549 cell line\n",
    "a549_samples = sample_metadata[sample_metadata[\"cell_line\"].str.contains(\"A549\", na=False)]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Found {len(a549_samples)} samples with A549 cell line:\")\n",
    "print(a549_samples[[\"srx_accession\", \"tissue\", \"disease\", \"perturbation\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34 samples with A549 cell line:\n",
      "      srx_accession              tissue  \\\n",
      "531      ERX8792190               other   \n",
      "2708    SRX21897869               other   \n",
      "2854    SRX25289894                lung   \n",
      "3361    SRX17488180                 eye   \n",
      "3466    SRX17915869               other   \n",
      "3638    SRX19004457               ovary   \n",
      "4899    SRX24227811     endocrine gland   \n",
      "5137    SRX25289882               other   \n",
      "5253    SRX26771412               other   \n",
      "7881    SRX17150748                lung   \n",
      "7882    SRX17150749                lung   \n",
      "7883    SRX17150750                lung   \n",
      "7884    SRX17150747                lung   \n",
      "8473    SRX17915870               other   \n",
      "8500    SRX17941758                lung   \n",
      "8505    SRX17941757                lung   \n",
      "9522    SRX19215444                lung   \n",
      "9526    SRX19215443                lung   \n",
      "12529   SRX21897873                lung   \n",
      "12533   SRX21897872               other   \n",
      "12736   SRX22159982                lung   \n",
      "15533   SRX25289881                lung   \n",
      "15534   SRX25289889               other   \n",
      "15535   SRX25289885                lung   \n",
      "15536   SRX25289888                lung   \n",
      "15537   SRX25289887               other   \n",
      "15538   SRX25289879  respiratory system   \n",
      "15539   SRX25289890               other   \n",
      "15540   SRX25289886               other   \n",
      "15541   SRX25289891               other   \n",
      "15542   SRX25289884               other   \n",
      "15543   SRX25289880               other   \n",
      "15544   SRX25289893               other   \n",
      "15546   SRX25289892                lung   \n",
      "\n",
      "                                                 disease  \\\n",
      "531                                  lung adenocarcinoma   \n",
      "2708                                 lung adenocarcinoma   \n",
      "2854                                     prostate cancer   \n",
      "3361                    age-related macular degeneration   \n",
      "3466                Influenza A virus (A/WSN/1933(H1N1))   \n",
      "3638                                      ovarian cancer   \n",
      "4899             PitNET (Pituitary Neuroendocrine Tumor)   \n",
      "5137           infected with H1N1 (A/California/07/2009)   \n",
      "5253   cancer types such as melanoma, pancreatic canc...   \n",
      "7881            duodenal gastrointestinal stromal tumors   \n",
      "7882                                 lung adenocarcinoma   \n",
      "7883                                 lung adenocarcinoma   \n",
      "7884   hereditary neuropathy with liability to pressu...   \n",
      "8473                influenza A virus (A/WSN/1933(H1N1))   \n",
      "8500                                         lung cancer   \n",
      "8505                                       not specified   \n",
      "9522                                 lung adenocarcinoma   \n",
      "9526                                bacterial infections   \n",
      "12529                                lung adenocarcinoma   \n",
      "12533                                lung adenocarcinoma   \n",
      "12736                multidrug resistance in tumor cells   \n",
      "15533                     Autism Spectrum Disorder (ASD)   \n",
      "15534                                      not specified   \n",
      "15535                 Influenza A virus infection (H1N1)   \n",
      "15536     related to antibiotic practices and resistance   \n",
      "15537                   influenza virus infection (H3N2)   \n",
      "15538                 influenza A virus infection (H1N1)   \n",
      "15539                                      not specified   \n",
      "15540                                      not specified   \n",
      "15541                                      not specified   \n",
      "15542                                      not specified   \n",
      "15543                                      not specified   \n",
      "15544                                  colorectal cancer   \n",
      "15546                             Influenza (H3N2 virus)   \n",
      "\n",
      "                                            perturbation  \n",
      "531                    Ritonavir, gemcitabine, cisplatin  \n",
      "2708   CAR T cell therapy, SUV39H1 knockout, CD19 tum...  \n",
      "2854                         uninfected (mock treatment)  \n",
      "3361                        in vitro culture of iPSC-RPE  \n",
      "3466                                 NS1 4xstop (mutant)  \n",
      "3638                                        Bexmarilimab  \n",
      "4899                                ACME HS dissociation  \n",
      "5137                              8 hours post infection  \n",
      "5253   mixed sample treatments include DMSO, ARS-1620...  \n",
      "7881        irradiated A549 cells (6 Gy γ-ray treatment)  \n",
      "7882                                6 Gy γ-ray treatment  \n",
      "7883                                 irradiation (IR 6h)  \n",
      "7884                                         irradiation  \n",
      "8473                                wild-type (WT) virus  \n",
      "8500   lentiviral pool, tamoxifen-inducible Cas9, pur...  \n",
      "8505   lentiviral pool for expression of 120 gRNAs, t...  \n",
      "9522                                              unsure  \n",
      "9526   glyconanomaterials for combating bacterial inf...  \n",
      "12529           CAR T cell therapy with SUV39H1 knockout  \n",
      "12533               CAR T cell therapy, SUV39H1 knockout  \n",
      "12736  antineoplastic agents, mixed micelles for drug...  \n",
      "15533  Infected with H1N1 (A/California/07/2009), 8 h...  \n",
      "15534               infected with H3N2 (A/Perth/16/2009)  \n",
      "15535  Infected with H1N1 (A/California/07/2009), 8 h...  \n",
      "15536               infected with H3N2 (A/Perth/16/2009)  \n",
      "15537  infected with H3N2 (A/Perth/16/2009), 16 hours...  \n",
      "15538          infected with H1N1 (A/California/07/2009)  \n",
      "15539               infected with H3N2 (A/Perth/16/2009)  \n",
      "15540                                  uninfected (Mock)  \n",
      "15541               infected with H3N2 (A/Perth/16/2009)  \n",
      "15542            Infected (Cal07, 16 hours, Replicate 2)  \n",
      "15543          infected with H1N1 (A/California/07/2009)  \n",
      "15544  infected with H3N2, Cetuximab (anti-EGFR therapy)  \n",
      "15546  Infected with H3N2 (A/Perth/16/2009), 16 hours...  \n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/ERX8792190.h5ad to a549_data/ERX8792190.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX21897869.h5ad to a549_data/SRX21897869.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX25289894.h5ad to a549_data/SRX25289894.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX17488180.h5ad to a549_data/SRX17488180.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX17915869.h5ad to a549_data/SRX17915869.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX19004457.h5ad to a549_data/SRX19004457.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX24227811.h5ad to a549_data/SRX24227811.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX25289882.h5ad to a549_data/SRX25289882.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX26771412.h5ad to a549_data/SRX26771412.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX17150748.h5ad to a549_data/SRX17150748.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX17150749.h5ad to a549_data/SRX17150749.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX17150750.h5ad to a549_data/SRX17150750.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX17150747.h5ad to a549_data/SRX17150747.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX17915870.h5ad to a549_data/SRX17915870.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX17941758.h5ad to a549_data/SRX17941758.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX17941757.h5ad to a549_data/SRX17941757.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX19215444.h5ad to a549_data/SRX19215444.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX19215443.h5ad to a549_data/SRX19215443.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX21897873.h5ad to a549_data/SRX21897873.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX21897872.h5ad to a549_data/SRX21897872.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX22159982.h5ad to a549_data/SRX22159982.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX25289881.h5ad to a549_data/SRX25289881.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX25289889.h5ad to a549_data/SRX25289889.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX25289885.h5ad to a549_data/SRX25289885.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX25289888.h5ad to a549_data/SRX25289888.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX25289887.h5ad to a549_data/SRX25289887.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX25289879.h5ad to a549_data/SRX25289879.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX25289890.h5ad to a549_data/SRX25289890.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX25289886.h5ad to a549_data/SRX25289886.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX25289891.h5ad to a549_data/SRX25289891.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX25289884.h5ad to a549_data/SRX25289884.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX25289880.h5ad to a549_data/SRX25289880.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX25289893.h5ad to a549_data/SRX25289893.h5ad...\n",
      "Downloading gs://arc-ctc-scbasecamp/2025-02-25/h5ad/GeneFull_Ex50pAS/Homo_sapiens/SRX25289892.h5ad to a549_data/SRX25289892.h5ad...\n",
      "All A549 h5ad files downloaded to a549_data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create a directory to save the files\n",
    "output_dir = \"a549_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Download the files using gsutil\n",
    "for i, row in a549_samples.iterrows():\n",
    "    file_path = row[\"file_path\"]\n",
    "    output_file = os.path.join(output_dir, os.path.basename(file_path))\n",
    "    \n",
    "    print(f\"Downloading {file_path} to {output_file}...\")\n",
    "    \n",
    "    # Using subprocess to call gsutil\n",
    "    fs.get(file_path, output_file)\n",
    "\n",
    "print(f\"All A549 h5ad files downloaded to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import anndata\n",
    "\n",
    "# Directory containing the downloaded A549 files\n",
    "data_dir = \"a549_data\"\n",
    "\n",
    "# List all h5ad files in the directory\n",
    "a549_files = [file for file in os.listdir(data_dir) if file.endswith('.h5ad')]\n",
    "print(f\"Found {len(a549_files)} A549 h5ad files\")\n",
    "\n",
    "# Create output directories\n",
    "results_dir = \"a549_perturbation_analysis\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "fig_dir = os.path.join(results_dir, \"figures\")\n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "# Load all datasets\n",
    "adatas = []\n",
    "for file in a549_files:\n",
    "    file_path = os.path.join(data_dir, file)\n",
    "    print(f\"Loading {file}...\")\n",
    "    try:\n",
    "        adata = sc.read_h5ad(file_path)\n",
    "        # Extract accession ID from filename\n",
    "        accession = file.replace('.h5ad', '')\n",
    "        adata.obs['sample_id'] = accession\n",
    "        adatas.append(adata)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file}: {e}\")\n",
    "\n",
    "\n",
    "# Combine the data\n",
    "print(\"Combining data...\")\n",
    "combined = adatas[0].concatenate(adatas[1:], join='outer', index_unique='-')\n",
    "print(f\"Combined data shape: {combined.shape}\")\n",
    "\n",
    "# Basic preprocessing\n",
    "sc.pp.filter_cells(combined, min_genes=200)\n",
    "sc.pp.filter_genes(combined, min_cells=10)\n",
    "sc.pp.normalize_total(combined, target_sum=1e4)\n",
    "sc.pp.log1p(combined)\n",
    "\n",
    "import pyarrow.dataset as ds\n",
    "import gcsfs\n",
    "\n",
    "fs = gcsfs.GCSFileSystem()\n",
    "gcs_base_path = \"gs://arc-ctc-scbasecamp/2025-02-25/\"\n",
    "feature_type = \"GeneFull_Ex50pAS\"\n",
    "metadata_path = os.path.join(gcs_base_path, \"metadata\", feature_type)\n",
    "sample_metadata_path = os.path.join(metadata_path, \"Homo_sapiens\", \"sample_metadata.parquet\")\n",
    "sample_metadata = ds.dataset(sample_metadata_path, filesystem=fs, format=\"parquet\").to_table().to_pandas()\n",
    "\n",
    "# Filter for A549 cell line and extract perturbation information\n",
    "a549_metadata = sample_metadata[sample_metadata[\"cell_line\"].str.contains(\"A549\", na=False)]\n",
    "\n",
    "# Map sample_id to perturbation information\n",
    "id_to_perturbation = dict(zip(a549_metadata[\"srx_accession\"], a549_metadata[\"perturbation\"]))\n",
    "\n",
    "# Add perturbation information to the anndata object\n",
    "combined.obs['perturbation'] = combined.obs['sample_id'].map(id_to_perturbation).fillna('unknown')\n",
    "\n",
    "# Identify control samples (no perturbation) - look for keywords in perturbation column\n",
    "control_keywords = ['control', 'untreated', 'dmso', 'vehicle', 'none', 'mock']\n",
    "combined.obs['is_control'] = combined.obs['perturbation'].str.lower().apply(\n",
    "    lambda x: any(keyword in str(x).lower() for keyword in control_keywords) if pd.notna(x) else False\n",
    ")\n",
    "\n",
    "# If no explicit controls are found, try to identify them from the metadata context\n",
    "if combined.obs['is_control'].sum() == 0:\n",
    "    print(\"No explicit control samples found. Analyzing perturbation patterns...\")\n",
    "    \n",
    "    # Create a summary of perturbation conditions\n",
    "    perturbation_summary = combined.obs['perturbation'].value_counts()\n",
    "    print(perturbation_summary)\n",
    "    \n",
    "    # Ask user to specify control condition if automatic detection fails\n",
    "    print(\"Please manually review perturbation conditions and define controls.\")\n",
    "\n",
    "# Print summary of control vs treatment samples\n",
    "print(f\"Control samples: {combined.obs['is_control'].sum()}\")\n",
    "print(f\"Treatment samples: {(~combined.obs['is_control']).sum()}\")\n",
    "\n",
    "# Group perturbations by drug name where possible\n",
    "# This requires some text processing as perturbation descriptions vary\n",
    "def extract_drug_name(perturbation_text):\n",
    "    if pd.isna(perturbation_text):\n",
    "        return 'unknown'\n",
    "    \n",
    "    perturbation_text = str(perturbation_text).lower()\n",
    "    \n",
    "    # Skip control conditions\n",
    "    if any(keyword in perturbation_text for keyword in control_keywords):\n",
    "        return 'control'\n",
    "    \n",
    "    # Try to extract drug names - this would need refinement based on actual data\n",
    "    # Example logic - this should be adjusted based on your actual data format\n",
    "    if 'treated with' in perturbation_text:\n",
    "        parts = perturbation_text.split('treated with')\n",
    "        if len(parts) > 1:\n",
    "            drug_part = parts[1].strip()\n",
    "            # Take the first word as potential drug name\n",
    "            drug_name = drug_part.split()[0].strip(',.:;')\n",
    "            return drug_name\n",
    "    \n",
    "    # Add more extraction rules as needed\n",
    "    \n",
    "    # Default return the first 30 chars if no pattern matched\n",
    "    return perturbation_text[:30]\n",
    "\n",
    "combined.obs['drug'] = combined.obs['perturbation'].apply(extract_drug_name)\n",
    "\n",
    "# For each drug, perform hypothesis testing to identify differentially expressed genes\n",
    "control_cells = combined[combined.obs['is_control']]\n",
    "if len(control_cells) == 0:\n",
    "    print(\"Error: No control cells identified. Cannot perform differential expression analysis.\")\n",
    "    exit()\n",
    "\n",
    "# Create results dataframe to store findings\n",
    "results = pd.DataFrame()\n",
    "\n",
    "# Get unique drugs (excluding control)\n",
    "unique_drugs = combined.obs['drug'].unique()\n",
    "unique_drugs = [drug for drug in unique_drugs if drug != 'control']\n",
    "\n",
    "print(f\"Analyzing differential expression for {len(unique_drugs)} drugs...\")\n",
    "\n",
    "for drug in unique_drugs:\n",
    "    print(f\"Processing drug: {drug}\")\n",
    "    \n",
    "    # Get cells treated with this drug\n",
    "    drug_cells = combined[combined.obs['drug'] == drug]\n",
    "    \n",
    "    if len(drug_cells) < 10:\n",
    "        print(f\"  Skipping {drug}: too few cells ({len(drug_cells)})\")\n",
    "        continue\n",
    "    \n",
    "    # Perform differential expression analysis\n",
    "    try:\n",
    "        sc.tl.rank_genes_groups(combined, 'drug', groups=[drug], reference='control', method='wilcoxon')\n",
    "        \n",
    "        # Extract results for this drug\n",
    "        de_genes = sc.get.rank_genes_groups_df(combined, group=drug)\n",
    "        de_genes['drug'] = drug\n",
    "        \n",
    "        # Filter for significantly differentially expressed genes\n",
    "        significant_genes = de_genes[de_genes['pvals_adj'] < 0.05]\n",
    "        \n",
    "        # Add to results\n",
    "        results = pd.concat([results, significant_genes])\n",
    "        \n",
    "        # Create volcano plot for top genes\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.scatter(de_genes['logfoldchanges'], -np.log10(de_genes['pvals']), alpha=0.5)\n",
    "        \n",
    "        # Highlight significant genes\n",
    "        significant = (de_genes['pvals_adj'] < 0.05)\n",
    "        plt.scatter(\n",
    "            de_genes.loc[significant, 'logfoldchanges'],\n",
    "            -np.log10(de_genes.loc[significant, 'pvals']),\n",
    "            color='red', alpha=0.8\n",
    "        )\n",
    "        \n",
    "        # Label top genes\n",
    "        top_genes = de_genes.nsmallest(10, 'pvals')\n",
    "        for _, gene in top_genes.iterrows():\n",
    "            plt.annotate(gene['names'], \n",
    "                        (gene['logfoldchanges'], -np.log10(gene['pvals'])),\n",
    "                        xytext=(5, 5), textcoords='offset points')\n",
    "        \n",
    "        plt.axhline(-np.log10(0.05), linestyle='--', color='gray')\n",
    "        plt.axvline(-1, linestyle='--', color='gray')\n",
    "        plt.axvline(1, linestyle='--', color='gray')\n",
    "        \n",
    "        plt.xlabel('Log Fold Change')\n",
    "        plt.ylabel('-log10(p-value)')\n",
    "        plt.title(f'Differential Expression: {drug} vs Control')\n",
    "        plt.savefig(os.path.join(fig_dir, f'volcano_plot_{drug}.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        # Save top genes list for this drug\n",
    "        top_n = min(50, len(significant_genes))\n",
    "        significant_genes.head(top_n).to_csv(\n",
    "            os.path.join(results_dir, f'top_genes_{drug}.csv'), index=False)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error analyzing {drug}: {e}\")\n",
    "\n",
    "# Save combined results\n",
    "if not results.empty:\n",
    "    # Summary of all drugs and their significant genes\n",
    "    drug_gene_counts = results.groupby('drug').size().reset_index(name='sig_gene_count')\n",
    "    drug_gene_counts = drug_gene_counts.sort_values('sig_gene_count', ascending=False)\n",
    "    \n",
    "    # Save summary\n",
    "    drug_gene_counts.to_csv(os.path.join(results_dir, 'drug_affected_gene_counts.csv'), index=False)\n",
    "    \n",
    "    # Save full results\n",
    "    results.to_csv(os.path.join(results_dir, 'all_drug_gene_effects.csv'), index=False)\n",
    "    \n",
    "    # Create summary figure of drugs by number of affected genes\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='drug', y='sig_gene_count', data=drug_gene_counts)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title('Number of Significantly Affected Genes by Drug')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(fig_dir, 'drug_gene_count_summary.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Identify most frequently affected genes across multiple drugs\n",
    "    gene_drug_counts = results.groupby('names').size().reset_index(name='drug_count')\n",
    "    gene_drug_counts = gene_drug_counts.sort_values('drug_count', ascending=False)\n",
    "    \n",
    "    # Save genes affected by multiple drugs\n",
    "    gene_drug_counts.head(100).to_csv(os.path.join(results_dir, 'multi_drug_affected_genes.csv'), index=False)\n",
    "    \n",
    "    # Create heatmap of top genes across drugs\n",
    "    top_genes = gene_drug_counts.head(20)['names'].tolist()\n",
    "    top_drugs = drug_gene_counts.head(15)['drug'].tolist()\n",
    "    \n",
    "    # Filter results for top genes and drugs\n",
    "    heatmap_data = results[\n",
    "        (results['names'].isin(top_genes)) & \n",
    "        (results['drug'].isin(top_drugs))\n",
    "    ]\n",
    "    \n",
    "    if not heatmap_data.empty:\n",
    "        # Create pivot table for heatmap\n",
    "        pivot_data = heatmap_data.pivot_table(\n",
    "            index='names', \n",
    "            columns='drug', \n",
    "            values='logfoldchanges',\n",
    "            fill_value=0\n",
    "        )\n",
    "        \n",
    "        # Create heatmap\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        sns.heatmap(pivot_data, cmap='RdBu_r', center=0, annot=False)\n",
    "        plt.title('Log Fold Changes of Top Genes Across Drugs')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(fig_dir, 'gene_drug_heatmap.png'))\n",
    "        plt.close()\n",
    "\n",
    "print(f\"Analysis complete. Results saved to {results_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"a549_combined_data.h5ad\"\n",
    "combined.write_h5ad(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 34 A549 h5ad files\n",
      "Processed metadata for SRX17915870.h5ad\n",
      "Processed metadata for SRX17150748.h5ad\n",
      "Processed metadata for SRX25289884.h5ad\n",
      "Processed metadata for SRX21897873.h5ad\n",
      "Processed metadata for SRX25289889.h5ad\n",
      "Processed metadata for SRX25289882.h5ad\n",
      "Processed metadata for SRX17150747.h5ad\n",
      "Processed metadata for SRX25289890.h5ad\n",
      "Processed metadata for ERX8792190.h5ad\n",
      "Processed metadata for SRX19215443.h5ad\n",
      "Processed metadata for SRX25289894.h5ad\n",
      "Processed metadata for SRX17915869.h5ad\n",
      "Processed metadata for SRX25289893.h5ad\n",
      "Processed metadata for SRX17488180.h5ad\n",
      "Processed metadata for SRX26771412.h5ad\n",
      "Processed metadata for SRX17150749.h5ad\n",
      "Processed metadata for SRX25289891.h5ad\n",
      "Processed metadata for SRX21897869.h5ad\n",
      "Processed metadata for SRX19215444.h5ad\n",
      "Processed metadata for SRX22159982.h5ad\n",
      "Processed metadata for SRX17150750.h5ad\n",
      "Processed metadata for SRX25289892.h5ad\n",
      "Processed metadata for SRX25289886.h5ad\n",
      "Processed metadata for SRX25289887.h5ad\n",
      "Processed metadata for SRX17941758.h5ad\n",
      "Processed metadata for SRX24227811.h5ad\n",
      "Processed metadata for SRX21897872.h5ad\n",
      "Processed metadata for SRX17941757.h5ad\n",
      "Processed metadata for SRX25289881.h5ad\n",
      "Processed metadata for SRX25289879.h5ad\n",
      "Processed metadata for SRX25289885.h5ad\n",
      "Processed metadata for SRX25289888.h5ad\n",
      "Processed metadata for SRX25289880.h5ad\n",
      "Processed metadata for SRX19004457.h5ad\n",
      "Saved metadata for 34 files\n",
      "Created documentation in a549_combined_data/README.txt\n"
     ]
    }
   ],
   "source": [
    "metadata = []\n",
    "output_dir = \"a549_combined_data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# List all h5ad files in the directory\n",
    "a549_files = [file for file in os.listdir(data_dir) if file.endswith('.h5ad')]\n",
    "print(f\"Found {len(a549_files)} A549 h5ad files\")\n",
    "\n",
    "# Save basic metadata for each file\n",
    "for file in a549_files:\n",
    "    file_path = os.path.join(data_dir, file)\n",
    "    try:\n",
    "        # Load basic info without reading full data\n",
    "        adata = sc.read_h5ad(file_path, backed='r')\n",
    "        \n",
    "        metadata.append({\n",
    "            'filename': file,\n",
    "            'filepath': file_path,\n",
    "            'n_obs': adata.n_obs,\n",
    "            'n_vars': adata.n_vars,\n",
    "            'obs_keys': list(adata.obs.keys()),\n",
    "            'var_keys': list(adata.var.keys()),\n",
    "        })\n",
    "        \n",
    "        print(f\"Processed metadata for {file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "# Save metadata as CSV\n",
    "metadata_df = pd.DataFrame(metadata)\n",
    "metadata_df.to_csv(os.path.join(output_dir, \"a549_files_metadata.csv\"), index=False)\n",
    "print(f\"Saved metadata for {len(metadata_df)} files\")\n",
    "\n",
    "# Create a readme file with loading instructions\n",
    "with open(os.path.join(output_dir, \"README.txt\"), 'w') as f:\n",
    "    f.write(\"A549 Cell Line Data Collection\\n\")\n",
    "    f.write(\"=============================\\n\\n\")\n",
    "    f.write(f\"This directory contains metadata for {len(metadata_df)} A549 cell line h5ad files.\\n\\n\")\n",
    "    f.write(\"To recreate the combined dataset, use the following Python code:\\n\\n\")\n",
    "    f.write(\"```python\\n\")\n",
    "    f.write(\"import scanpy as sc\\n\")\n",
    "    f.write(\"import pandas as pd\\n\")\n",
    "    f.write(\"import os\\n\\n\")\n",
    "    f.write(\"# Load the metadata\\n\")\n",
    "    f.write(\"metadata = pd.read_csv('a549_files_metadata.csv')\\n\\n\")\n",
    "    f.write(\"# Load all datasets\\n\")\n",
    "    f.write(\"adatas = []\\n\")\n",
    "    f.write(\"for file_path in metadata['filepath']:\\n\")\n",
    "    f.write(\"    adata = sc.read_h5ad(file_path)\\n\")\n",
    "    f.write(\"    # Add sample ID from filename\\n\")\n",
    "    f.write(\"    adata.obs['sample_id'] = os.path.basename(file_path).replace('.h5ad', '')\\n\")\n",
    "    f.write(\"    adatas.append(adata)\\n\\n\")\n",
    "    f.write(\"# Combine datasets\\n\")\n",
    "    f.write(\"combined = adatas[0].concatenate(adatas[1:], join='outer', index_unique='-')\\n\")\n",
    "    f.write(\"print(f'Combined data shape: {combined.shape}')\\n\")\n",
    "    f.write(\"```\\n\")\n",
    "\n",
    "print(f\"Created documentation in {output_dir}/README.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scbasecamp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
